{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b05f708-6815-4ba5-838e-5148e75e95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mp4, test_depth = \"./raw_data/rgb_20250710_150214\", \"./raw_data/depth_20250710_150214\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d799c849-945f-45ba-a99a-b99a7207ff9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mframe_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrameProcessor\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmock_camera\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MockCamera\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdepth_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DepthProcessor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Gelendjik\\frame_processor.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbaggage_detector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaggageDetector\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbaggage_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaggageTracker\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpoint_cloud_reconstructor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PointCloudReconstructor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Gelendjik\\baggage_detector.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\ultralytics\\__init__.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOMP_NUM_THREADS\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      9\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mOMP_NUM_THREADS\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\ultralytics\\models\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfastsam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrtdetr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\ultralytics\\models\\fastsam\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\ultralytics\\models\\fastsam\\model.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\ultralytics\\engine\\model.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcfg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\torch\\__init__.py:270\u001b[39m\n\u001b[32m    266\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    268\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in path/nvidia/lib_folder/lib or path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\AISchool\\Lib\\site-packages\\torch\\__init__.py:246\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    244\u001b[39m is_loaded = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     res = \u001b[43mkernel32\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     last_error = ctypes.get_last_error()\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error != \u001b[32m126\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from frame_processor import FrameProcessor\n",
    "from mock_camera import MockCamera\n",
    "from depth_processor import DepthProcessor\n",
    "import numpy as np\n",
    "\n",
    "from config import Config \n",
    "Config.POINT_CLOUD_STRIDE=1\n",
    "\n",
    "# Инициализация\n",
    "Config.CAMERA_INTRINSICS={\n",
    "                'fx': 390.4425964355469, \n",
    "                'fy': 390.4425964355469,\n",
    "                'cx': 320.0,\n",
    "                'cy': 240.0,\n",
    "                'depth_scale': 0.001\n",
    "            }\n",
    "Config.MAX_OBSERVATIONS=30\n",
    "camera_intrinsics = Config.CAMERA_INTRINSICS\n",
    "#Config.CAMERA_INTRINSICS\n",
    "#camera = RealSenseCamera()\n",
    "camera = MockCamera(rgb_folder=test_mp4, depth_folder=test_depth)\n",
    "processor = FrameProcessor(camera_intrinsics)\n",
    "depth_processor = DepthProcessor()\n",
    "processor.set_tracking_enabled(True)\n",
    "camera.start()\n",
    "\n",
    "# Обработка и отображение\n",
    "while True:\n",
    "   color, depth = camera.get_frames()\n",
    "   if color is None or depth is None:\n",
    "       break\n",
    "   \n",
    "   # Обработка кадра\n",
    "   results = processor.process_frame(color, depth, is_calibration=True)\n",
    "   # Отображение результата (combined = RGB + Depth + Cleaned)\n",
    "   cv2.imshow('Processed Video', results['combined'])\n",
    "\n",
    "   if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "       break\n",
    "\n",
    "camera.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Вывод статистики\n",
    "print(f\"Обработано кадров: {processor.frame_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b354e4-942b-4aa5-bdaa-8db8a1149e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Настройка пайплайна\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Запуск камеры\n",
    "pipeline.start(config)\n",
    "\n",
    "# Очередь кадров\n",
    "frames = pipeline.wait_for_frames()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "color_frame = frames.get_color_frame()\n",
    "spatial = rs.spatial_filter()\n",
    "depth_frame = spatial.process(depth_frame)\n",
    "# Преобразование в numpy\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "H, W = color_image.shape[:2]\n",
    "\n",
    "# Размер вырезаемого квадрата\n",
    "square_size = 100  # пикселей\n",
    "cx, cy = W // 2, H // 2\n",
    "\n",
    "# Границы квадрата\n",
    "x0 = cx - square_size // 2\n",
    "x1 = cx + square_size // 2\n",
    "y0 = cy - square_size // 2\n",
    "y1 = cy + square_size // 2\n",
    "\n",
    "# Создаём маску: True — оставить, False — вырезать\n",
    "mask = np.ones((H, W), dtype=bool)\n",
    "mask[y0:y1, x0:x1] = False\n",
    "\n",
    "# Получение профиля камеры\n",
    "pc = rs.pointcloud()\n",
    "points = pc.calculate(depth_frame)\n",
    "pc.map_to(color_frame)\n",
    "vtx = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "tex = np.asanyarray(points.get_texture_coordinates()).view(np.float32).reshape(-1, 2)\n",
    "mask_flat = mask.flatten()\n",
    "\n",
    "# Отфильтровать точки и цвета\n",
    "vtx_masked = vtx[mask_flat]\n",
    "# Используем Open3D\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(vtx_masked)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8032a-2ca3-4241-a893-a7de7f4eac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a880b64-daa4-4dfc-b8b2-96dd34f41037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from frame_processor import FrameProcessor\n",
    "from mock_camera import MockCamera\n",
    "from depth_processor import DepthProcessor\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from realsense_camera import RealSenseCamera\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "from config import Config \n",
    "Config.POINT_CLOUD_STRIDE=1\n",
    "\n",
    "\n",
    "Config.MAX_OBSERVATIONS=30\n",
    "camera_intrinsics = Config.CAMERA_INTRINSICS\n",
    "#Config.CAMERA_INTRINSICS\n",
    "camera = RealSenseCamera(apply_filters=True)\n",
    "#camera = MockCamera(rgb_folder=test_mp4, depth_folder=test_depth)\n",
    "processor = FrameProcessor(camera_intrinsics)\n",
    "depth_processor = DepthProcessor()\n",
    "processor.set_tracking_enabled(True)\n",
    "camera.start()\n",
    "\n",
    "# Обработка и отображение\n",
    "\"\"\"\n",
    "pc = rs.pointcloud()\n",
    "points = pc.calculate(depth)\n",
    "pc.map_to(color_frame)\n",
    "vtx = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "tex = np.asanyarray(points.get_texture_coordinates()).view(np.float32).reshape(-1, 2)\n",
    "\"\"\"\n",
    "color_image, depth_image = camera.get_frames()\n",
    "depth_o3d = o3d.geometry.Image(depth.astype(np.uint16))\n",
    "o3d_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "o3d_intrinsics.set_intrinsics(\n",
    "                width=480, height=640,\n",
    "                fx=camera_intrinsics['fx'],\n",
    "                fy=camera_intrinsics['fy'],\n",
    "                cx=camera_intrinsics['cx'],\n",
    "                cy=camera_intrinsics['cy']\n",
    "            )\n",
    "pcd = o3d.geometry.PointCloud.create_from_depth_image(\n",
    "                depth_o3d, o3d_intrinsics, depth_scale=1000.0, stride=Config.POINT_CLOUD_STRIDE\n",
    "            )\n",
    "# Используем Open3D\n",
    "#pcd = o3d.geometry.PointCloud()\n",
    "#pcd.points = o3d.utility.Vector3dVector(vtx)\n",
    "#pcd.colors = o3d.utility.Vector3dVector(color_image.reshape(-1, 3) / 255.0)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5319cac-9774-402e-97c0-7babea367565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео 1: 720x1280, FPS: 60\n",
      "Видео 2: 644x1428\n",
      "Записываем первое видео...\n",
      "Первое видео - кадров: 30\n",
      "Первое видео - кадров: 60\n",
      "Первое видео - кадров: 90\n",
      "Первое видео - кадров: 120\n",
      "Первое видео - кадров: 150\n",
      "Первое видео - кадров: 180\n",
      "Первое видео - кадров: 210\n",
      "Первое видео - кадров: 240\n",
      "Первое видео - кадров: 270\n",
      "Первое видео - кадров: 300\n",
      "Первое видео - кадров: 330\n",
      "Пропускаем 25 кадров второго видео...\n",
      "Записываем второе видео...\n",
      "Общий счетчик кадров: 360\n",
      "Общий счетчик кадров: 390\n",
      "Общий счетчик кадров: 420\n",
      "Готово! Сохранено 439 кадров в merged_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def merge_videos(video1_path, video2_path, output_path, skip_frames=0):\n",
    "    \"\"\"\n",
    "    Объединяет два MP4 видео последовательно (одно за другим)\n",
    "    \n",
    "    Args:\n",
    "        video1_path: путь к первому видео\n",
    "        video2_path: путь ко второму видео\n",
    "        output_path: путь для сохранения результата\n",
    "        skip_frames: количество кадров для пропуска у второго видео\n",
    "    \"\"\"\n",
    "    \n",
    "    # Открываем видео\n",
    "    cap1 = cv2.VideoCapture(video1_path)\n",
    "    cap2 = cv2.VideoCapture(video2_path)\n",
    "    \n",
    "    # Получаем параметры первого видео (оно задает размер)\n",
    "    fps = int(cap1.get(cv2.CAP_PROP_FPS))\n",
    "    width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Размеры второго видео\n",
    "    width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Видео 1: {width1}x{height1}, FPS: {fps}\")\n",
    "    print(f\"Видео 2: {width2}x{height2}\")\n",
    "    \n",
    "    # Создаем видео писатель\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width1, height1))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    # Записываем все кадры первого видео\n",
    "    print(\"Записываем первое видео...\")\n",
    "    while True:\n",
    "        ret, frame = cap1.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Первое видео - кадров: {frame_count}\")\n",
    "    \n",
    "    # Пропускаем кадры у второго видео\n",
    "    print(f\"Пропускаем {skip_frames} кадров второго видео...\")\n",
    "    for _ in range(skip_frames):\n",
    "        ret, _ = cap2.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "    # Записываем кадры второго видео\n",
    "    print(\"Записываем второе видео...\")\n",
    "    while True:\n",
    "        ret, frame = cap2.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Изменяем размер кадра под первое видео\n",
    "        frame = cv2.resize(frame, (width1, height1))\n",
    "        \n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Общий счетчик кадров: {frame_count}\")\n",
    "    \n",
    "    # Освобождаем ресурсы\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Готово! Сохранено {frame_count} кадров в {output_path}\")\n",
    "\n",
    "# Пример использования\n",
    "video1_path = \"school_data/1.mp4\"\n",
    "video2_path = \"school_data/2.mp4\"\n",
    "output_path = \"merged_video.mp4\"\n",
    "skip_frames = 25  # пропустить первые 10 кадров у второго видео\n",
    "\n",
    "merge_videos(video1_path, video2_path, output_path, skip_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a14f6-d975-41a3-81d1-b014684bc863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
